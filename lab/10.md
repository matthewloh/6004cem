Week10 â€“ Derived Data Types
Sample A: Using MPI_Type_create_struct
#include <stdio.h>
#include <mpi.h>

typedef struct {
float x;
int y;
} MyStruct;

int main(int argc, char \*argv[]) {
int rank;
MyStruct data;

    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    // Step 1: Describe the structure using MPI derived type
    MPI_Datatype MPI_MyStruct;
    int block_lengths[2] = {1, 1};  // One float and one int
    MPI_Aint displacements[2];
    MPI_Datatype types[2] = {MPI_FLOAT, MPI_INT};

    // Compute displacements
    displacements[0] = offsetof(MyStruct, x);
    displacements[1] = offsetof(MyStruct, y);

    MPI_Type_create_struct(2, block_lengths, displacements, types, &MPI_MyStruct);
    MPI_Type_commit(&MPI_MyStruct);

    if (rank == 0) {
        data.x = 3.14;
        data.y = 42;
        MPI_Send(&data, 1, MPI_MyStruct, 1, 0, MPI_COMM_WORLD);
        printf("Process 0 sent: x = %.2f, y = %d\n", data.x, data.y);
    } else if (rank == 1) {
        MPI_Recv(&data, 1, MPI_MyStruct, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        printf("Process 1 received: x = %.2f, y = %d\n", data.x, data.y);
    }

    MPI_Type_free(&MPI_MyStruct);
    MPI_Finalize();
    return 0;

}

Sample B: Using MPI_Type_vector
#include <stdio.h>
#include <mpi.h>

int main(int argc, char \*argv[]) {
int rank;
const int rows = 4, cols = 5;
float matrix[rows][cols];

    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    // Create vector type for a column
    MPI_Datatype column_type;
    MPI_Type_vector(rows, 1, cols, MPI_FLOAT, &column_type);
    MPI_Type_commit(&column_type);

    if (rank == 0) {
        // Initialize matrix with values
        printf("Process 0 original matrix:\n");
        for (int i = 0; i < rows; i++) {
            for (int j = 0; j < cols; j++) {
                matrix[i][j] = i * cols + j;  // e.g., matrix[i][j] = 5*i + j
                printf("%5.1f ", matrix[i][j]);
            }
            printf("\n");
        }

        // Send column 2 (3rd column)
        MPI_Send(&matrix[0][2], 1, column_type, 1, 0, MPI_COMM_WORLD);
        printf("Process 0 sent column 2\n");

    } else if (rank == 1) {
        float column_data[rows];
        MPI_Recv(column_data, rows, MPI_FLOAT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);

        printf("Process 1 received column data:\n");
        for (int i = 0; i < rows; i++) {
            printf("Row %d: %.1f\n", i, column_data[i]);
        }
    }

    MPI_Type_free(&column_type);
    MPI_Finalize();
    return 0;

}

Questions:

1. Why does MPI require users to define derived data types when sending non-contiguous or structured data? What limitations of basic MPI data types does this address?

2. Compare MPI_Type_vector, MPI_Type_contiguous, and MPI_Type_create_struct. What kinds of memory layouts is each suited for? Provide an example use case for each.

3. How does defining a derived datatype improve the readability and maintainability of MPI code that sends structured data like C structs?

4. Does using derived data types improve performance compared to manually packing and sending data using multiple MPI_Send calls? Why or why not? Under what circumstances might packing still be preferred?

5. How can defining a derived data type reduce the number of communication calls in a program, and what implications does this have for performance in large-scale parallel systems?
